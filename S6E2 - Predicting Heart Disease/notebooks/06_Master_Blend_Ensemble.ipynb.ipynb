{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PROJECT: Kaggle Playground Series - S6E2 (Heart Disease)\n",
        "# MISSION: The Master Blend (Optimized XGBoost + LightGBM)\n",
        "# ==============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from google.colab import drive\n",
        "\n",
        "# --- STEP 1: MOUNT & LOAD ---\n",
        "drive.mount('/content/drive')\n",
        "TRAIN_PATH = '/content/drive/MyDrive/Nihal Data/kaggle/S6E1 - heart/train.csv'\n",
        "TEST_PATH = '/content/drive/MyDrive/Nihal Data/kaggle/S6E1 - heart/test.csv'\n",
        "\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test = pd.read_csv(TEST_PATH)\n",
        "\n",
        "# --- STEP 2: PREPARATION ---\n",
        "target_mapping = {'Absence': 0, 'Presence': 1}\n",
        "y = train['Heart Disease'].map(target_mapping)\n",
        "X = train.drop(['id', 'Heart Disease'], axis=1)\n",
        "X_test = test.drop(['id'], axis=1)\n",
        "\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    X[col] = X[col].astype('category').cat.codes\n",
        "    X_test[col] = X_test[col].astype('category').cat.codes\n",
        "\n",
        "# --- STEP 3: THE EXPERT COUNCIL ---\n",
        "\n",
        "# Your winning XGBoost parameters from Trial 4\n",
        "xgb_params = {\n",
        "    'n_estimators': 3000,\n",
        "    'learning_rate': 0.0524336233119705,\n",
        "    'max_depth': 4,\n",
        "    'subsample': 0.8174286638784904,\n",
        "    'colsample_bytree': 0.5096944467506977,\n",
        "    'min_child_weight': 10,\n",
        "    'tree_method': 'hist',\n",
        "    'device': 'cuda',\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# A robust LightGBM configuration\n",
        "lgb_params = {\n",
        "    'n_estimators': 3000,\n",
        "    'learning_rate': 0.03,\n",
        "    'num_leaves': 31,\n",
        "    'device': 'gpu',\n",
        "    'random_state': 42,\n",
        "    'verbosity': -1\n",
        "}\n",
        "\n",
        "# --- STEP 4: TRAINING THE COUNCIL ---\n",
        "print(\"Training Optimized XGBoost...\")\n",
        "xgb_model = XGBClassifier(**xgb_params)\n",
        "xgb_model.fit(X, y)\n",
        "xgb_preds = xgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Training Optimized LightGBM...\")\n",
        "lgb_model = LGBMClassifier(**lgb_params)\n",
        "lgb_model.fit(X, y)\n",
        "lgb_preds = lgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# --- STEP 5: THE WEIGHTED BLEND ---\n",
        "# I am giving XGBoost more weight because we know it's a proven winner.\n",
        "final_preds = (0.7 * xgb_preds) + (0.3 * lgb_preds)\n",
        "\n",
        "# --- STEP 6: FINAL SUBMISSION ---\n",
        "submission = pd.DataFrame({'id': test['id'], 'Heart Disease': final_preds})\n",
        "submission.to_csv('submission_v6_master_blend.csv', index=False)\n",
        "\n",
        "print(\"Final Master Blend 'submission_v6_master_blend.csv' generated.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4e3Edz1322O",
        "outputId": "5f069c02-4ea0-454f-d83a-80b78abbefd3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Training Optimized XGBoost...\n",
            "Training Optimized LightGBM...\n",
            "Final Master Blend 'submission_v6_master_blend.csv' generated.\n"
          ]
        }
      ]
    }
  ]
}