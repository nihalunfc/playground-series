{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PROJECT: Kaggle Playground Series - S6E2 (Heart Disease)\n",
        "# MISSION: Pseudo-Labeling (Augmenting the Training Set)\n",
        "# ==============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from google.colab import drive\n",
        "\n",
        "# --- STEP 1: MOUNT & LOAD ---\n",
        "drive.mount('/content/drive')\n",
        "TRAIN_PATH = '/content/drive/MyDrive/Nihal Data/kaggle/S6E1 - heart/train.csv'\n",
        "TEST_PATH = '/content/drive/MyDrive/Nihal Data/kaggle/S6E1 - heart/test.csv'\n",
        "\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test = pd.read_csv(TEST_PATH)\n",
        "\n",
        "# Preparation\n",
        "target_mapping = {'Absence': 0, 'Presence': 1}\n",
        "train['target'] = train['Heart Disease'].map(target_mapping)\n",
        "\n",
        "X = train.drop(['id', 'Heart Disease', 'target'], axis=1)\n",
        "y = train['target']\n",
        "X_test = test.drop(['id'], axis=1)\n",
        "\n",
        "# Categorical Encoding\n",
        "for col in X.columns:\n",
        "    if X[col].dtype == 'object':\n",
        "        X[col] = X[col].astype('category').cat.codes\n",
        "        X_test[col] = X_test[col].astype('category').cat.codes\n",
        "\n",
        "# --- STEP 2: GENERATE PSEUDO-LABELS ---\n",
        "# Using your best parameters from Trial 4\n",
        "best_params = {\n",
        "    'n_estimators': 1000,\n",
        "    'learning_rate': 0.0524,\n",
        "    'max_depth': 4,\n",
        "    'subsample': 0.817,\n",
        "    'colsample_bytree': 0.509,\n",
        "    'tree_method': 'hist',\n",
        "    'device': 'cuda',\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "model = XGBClassifier(**best_params)\n",
        "model.fit(X, y)\n",
        "test_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Identify highly confident predictions (Top and Bottom 5%)\n",
        "pseudo_limit = 0.02 # Confidence threshold\n",
        "high_conf_presence = test_probs > (1 - pseudo_limit)\n",
        "high_conf_absence = test_probs < pseudo_limit\n",
        "\n",
        "# Create Pseudo-labeled dataset\n",
        "pseudo_X = X_test[high_conf_presence | high_conf_absence].copy()\n",
        "pseudo_y = (test_probs[high_conf_presence | high_conf_absence] > 0.5).astype(int)\n",
        "\n",
        "# --- STEP 3: AUGMENTED TRAINING ---\n",
        "# Combine original train data with pseudo-labeled test data\n",
        "X_augmented = pd.concat([X, pseudo_X])\n",
        "y_augmented = pd.concat([y, pd.Series(pseudo_y)])\n",
        "\n",
        "print(f\"Original Train Size: {len(X)}\")\n",
        "print(f\"Added Pseudo-labels: {len(pseudo_X)}\")\n",
        "\n",
        "# Re-train on the combined set\n",
        "final_model = XGBClassifier(**best_params)\n",
        "final_model.fit(X_augmented, y_augmented)\n",
        "\n",
        "# --- STEP 4: FINAL SUBMISSION ---\n",
        "final_probs = final_model.predict_proba(X_test)[:, 1]\n",
        "submission = pd.DataFrame({'id': test['id'], 'Heart Disease': final_probs})\n",
        "submission.to_csv('submission_v8_pseudo.csv', index=False)\n",
        "\n",
        "print(\"Pseudo-labeled submission 'submission_v8_pseudo.csv' generated.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx18GrI772Gk",
        "outputId": "abd48a12-e022-4c06-9932-9c545bdd34ea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Original Train Size: 630000\n",
            "Added Pseudo-labels: 83501\n",
            "Pseudo-labeled submission 'submission_v8_pseudo.csv' generated.\n"
          ]
        }
      ]
    }
  ]
}