{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PROJECT: Kaggle Playground Series - S6E2 (Heart Disease)\n",
        "# MISSION: The Grand Hybrid (Blending Stacking + Pseudo-Labeling)\n",
        "# ==============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# --- STEP 1: MOUNT & LOAD ---\n",
        "drive.mount('/content/drive')\n",
        "TRAIN_PATH = '/content/drive/MyDrive/Nihal Data/kaggle/S6E1 - heart/train.csv'\n",
        "TEST_PATH = '/content/drive/MyDrive/Nihal Data/kaggle/S6E1 - heart/test.csv'\n",
        "\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test = pd.read_csv(TEST_PATH)\n",
        "\n",
        "target_mapping = {'Absence': 0, 'Presence': 1}\n",
        "y = train['Heart Disease'].map(target_mapping)\n",
        "X = train.drop(['id', 'Heart Disease'], axis=1)\n",
        "X_test = test.drop(['id'], axis=1)\n",
        "\n",
        "# Categorical Encoding\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    X[col] = X[col].astype('category').cat.codes\n",
        "    X_test[col] = X_test[col].astype('category').cat.codes\n",
        "\n",
        "# ==============================================================================\n",
        "# PART A: RECREATING THE GOLD MEDAL (Trial 07 Stacking)\n",
        "# ==============================================================================\n",
        "print(\"1. Regenerating Trial 07 (Stacking)...\")\n",
        "\n",
        "# 1. Optimized XGBoost\n",
        "xgb_params = {\n",
        "    'n_estimators': 3000,\n",
        "    'learning_rate': 0.0524336,\n",
        "    'max_depth': 4,\n",
        "    'subsample': 0.817428,\n",
        "    'colsample_bytree': 0.50969,\n",
        "    'min_child_weight': 10,\n",
        "    'tree_method': 'hist',\n",
        "    'n_jobs': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# 2. Standard LightGBM (The one that worked best!)\n",
        "lgb_params = {\n",
        "    'n_estimators': 1000,\n",
        "    'learning_rate': 0.03,\n",
        "    'num_leaves': 63,\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "base_models = [\n",
        "    ('xgb', XGBClassifier(**xgb_params)),\n",
        "    ('lgb', LGBMClassifier(**lgb_params))\n",
        "]\n",
        "\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=LogisticRegression(),\n",
        "    cv=5,\n",
        "    stack_method='predict_proba',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "stack_model.fit(X, y)\n",
        "pred_stack = stack_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# ==============================================================================\n",
        "# PART B: RECREATING THE SILVER MEDAL (Trial 08 Pseudo-Labeling)\n",
        "# ==============================================================================\n",
        "print(\"2. Regenerating Trial 08 (Pseudo-Labeling)...\")\n",
        "\n",
        "# First pass to get high-confidence rows\n",
        "model_temp = XGBClassifier(**xgb_params)\n",
        "model_temp.fit(X, y)\n",
        "temp_probs = model_temp.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Identify pseudo-labels (Top/Bottom 2% confidence)\n",
        "pseudo_limit = 0.02\n",
        "high_conf_idx = (temp_probs > (1 - pseudo_limit)) | (temp_probs < pseudo_limit)\n",
        "\n",
        "pseudo_X = X_test[high_conf_idx].copy()\n",
        "pseudo_y = (temp_probs[high_conf_idx] > 0.5).astype(int)\n",
        "\n",
        "# Augment Training Data\n",
        "X_aug = pd.concat([X, pseudo_X])\n",
        "y_aug = pd.concat([y, pd.Series(pseudo_y)])\n",
        "\n",
        "# Final Retrain on Augmented Data\n",
        "model_pseudo = XGBClassifier(**xgb_params)\n",
        "model_pseudo.fit(X_aug, y_aug)\n",
        "pred_pseudo = model_pseudo.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# ==============================================================================\n",
        "# PART C: THE FINAL BLEND\n",
        "# ==============================================================================\n",
        "print(\"3. Blending Gold and Silver...\")\n",
        "\n",
        "# Weighted Average: 60% Stacking (More stable) + 40% Pseudo (More risky)\n",
        "final_preds = (0.6 * pred_stack) + (0.4 * pred_pseudo)\n",
        "\n",
        "submission = pd.DataFrame({'id': test['id'], 'Heart Disease': final_preds})\n",
        "submission.to_csv('submission_v13_grand_hybrid.csv', index=False)\n",
        "\n",
        "print(\"Grand Hybrid submission 'submission_v13_grand_hybrid.csv' generated.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi8286tcbnxv",
        "outputId": "e7d04e7c-fabe-4698-abda-b2b0fbced40f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "1. Regenerating Trial 07 (Stacking)...\n",
            "2. Regenerating Trial 08 (Pseudo-Labeling)...\n",
            "3. Blending Gold and Silver...\n",
            "Grand Hybrid submission 'submission_v13_grand_hybrid.csv' generated.\n"
          ]
        }
      ]
    }
  ]
}